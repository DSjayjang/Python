{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","from torch import nn"],"metadata":{"id":"OnRqxl1XPbW2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hLSAuna7PYHB"},"outputs":[],"source":["cfgs = { \"A\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n","         \"B\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n","         \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n","         \"E\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"] }"]},{"cell_type":"code","source":["class VGG(nn.Module):\n","    def __init__(self, cfg, batch_norm = False, num_classes = 1000, init_weights = True, drop_p = 0.5):\n","        super().__init__()\n","\n","        self.features = self.make_layers(cfg, batch_norm)\n","        self.avgpool = nn.AdaptiveAvgPool2d((7, 7)) # 7x7 이 되도록 avg pooling 하는 녀석\n","        self.classifier = nn.Sequential(nn.Linear(512 * 7 * 7, 4096),\n","                                        nn.ReLU(),\n","                                        nn.Dropout(p=drop_p),\n","                                        nn.Linear(4096, 4096),\n","                                        nn.ReLU(),\n","                                        nn.Dropout(p=drop_p),\n","                                        nn.Linear(4096, num_classes))\n","\n","        if init_weights:\n","            for m in self.modules():\n","                if isinstance(m, nn.Conv2d):\n","                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n","                    # mode=\"fan_out\" → backward gradient 분산 유지를 위해 fan_out 기준으로 std 계산\n","                    # nonlinearity=\"relu\" → ReLU가 반 깎으니까 분산도 반으로 줄어서 gain=√2로 분산을 보정\n","                    # 즉, 사용한 분산 값은 2/fan_out\n","                    if m.bias is not None:\n","                        nn.init.constant_(m.bias, 0)\n","                elif isinstance(m, nn.Linear):\n","                    nn.init.normal_(m.weight, mean=0, std=0.01)\n","                    nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = self.avgpool(x)\n","        x = torch.flatten(x, 1)\n","        x = self.classifier(x)\n","        return x\n","\n","    def make_layers(self, cfg, batch_norm = False):\n","        layers = []\n","        in_channels = 3\n","        for v in cfg: # cfg = [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"]\n","            if type(v) == int:\n","                if batch_norm:\n","                    layers += [nn.Conv2d(in_channels, v, 3, padding=1, bias=False), # 어차피 BN에 bias 포함\n","                               nn.BatchNorm2d(v),\n","                               nn.ReLU()]\n","                else:\n","                    layers += [nn.Conv2d(in_channels, v, 3, padding=1),\n","                               nn.ReLU()]\n","                in_channels = v\n","            else:\n","                layers += [nn.MaxPool2d(2)]\n","\n","        return nn.Sequential(*layers)"],"metadata":{"id":"C6E4BgO0QcZt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["avgpool = nn.AdaptiveAvgPool2d((4, 4))\n","print(avgpool(torch.randn(2,3,32,32)).shape)\n","x = torch.randn(2,3,2,2)\n","print(x)\n","print(avgpool(x)) # 작은 놈이 들어오면 늘려서라도 맞춰준다 # 값을 복제 시켜놓음"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oa1xtOB6oFuo","executionInfo":{"status":"ok","timestamp":1763991352791,"user_tz":-540,"elapsed":11,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"9c205b87-f54f-4a9f-9e95-697812ced5bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 3, 4, 4])\n","tensor([[[[ 0.5192, -1.3704],\n","          [-0.5193, -0.0531]],\n","\n","         [[-0.0574, -0.8994],\n","          [ 0.4007, -0.0164]],\n","\n","         [[-0.6730, -0.4228],\n","          [ 0.4561, -0.4095]]],\n","\n","\n","        [[[-0.5832, -0.7258],\n","          [ 0.9588, -1.1505]],\n","\n","         [[-0.7809, -0.4652],\n","          [ 0.5487,  1.2373]],\n","\n","         [[ 0.8288,  0.9699],\n","          [ 0.2145,  0.0349]]]])\n","tensor([[[[ 0.5192,  0.5192, -1.3704, -1.3704],\n","          [ 0.5192,  0.5192, -1.3704, -1.3704],\n","          [-0.5193, -0.5193, -0.0531, -0.0531],\n","          [-0.5193, -0.5193, -0.0531, -0.0531]],\n","\n","         [[-0.0574, -0.0574, -0.8994, -0.8994],\n","          [-0.0574, -0.0574, -0.8994, -0.8994],\n","          [ 0.4007,  0.4007, -0.0164, -0.0164],\n","          [ 0.4007,  0.4007, -0.0164, -0.0164]],\n","\n","         [[-0.6730, -0.6730, -0.4228, -0.4228],\n","          [-0.6730, -0.6730, -0.4228, -0.4228],\n","          [ 0.4561,  0.4561, -0.4095, -0.4095],\n","          [ 0.4561,  0.4561, -0.4095, -0.4095]]],\n","\n","\n","        [[[-0.5832, -0.5832, -0.7258, -0.7258],\n","          [-0.5832, -0.5832, -0.7258, -0.7258],\n","          [ 0.9588,  0.9588, -1.1505, -1.1505],\n","          [ 0.9588,  0.9588, -1.1505, -1.1505]],\n","\n","         [[-0.7809, -0.7809, -0.4652, -0.4652],\n","          [-0.7809, -0.7809, -0.4652, -0.4652],\n","          [ 0.5487,  0.5487,  1.2373,  1.2373],\n","          [ 0.5487,  0.5487,  1.2373,  1.2373]],\n","\n","         [[ 0.8288,  0.8288,  0.9699,  0.9699],\n","          [ 0.8288,  0.8288,  0.9699,  0.9699],\n","          [ 0.2145,  0.2145,  0.0349,  0.0349],\n","          [ 0.2145,  0.2145,  0.0349,  0.0349]]]])\n"]}]},{"cell_type":"code","source":["model = nn.Sequential(nn.Conv2d(3,32,3),\n","                      nn.ReLU(),\n","                      nn.Sequential(nn.Conv2d(32,64,3),\n","                                    nn.ReLU(),\n","                                    nn.Conv2d(64,64,3),\n","                                    nn.ReLU()),\n","                      nn.Conv2d(64,128,3))\n","[m for m in model.modules()]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iNSOhB1Ah030","executionInfo":{"status":"ok","timestamp":1763991352883,"user_tz":-540,"elapsed":37,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"8a4352e1-2287-4222-b22b-c1bb3ec1dae0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Sequential(\n","   (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n","   (1): ReLU()\n","   (2): Sequential(\n","     (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","     (1): ReLU()\n","     (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","     (3): ReLU()\n","   )\n","   (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n"," ),\n"," Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)),\n"," ReLU(),\n"," Sequential(\n","   (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n","   (1): ReLU()\n","   (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","   (3): ReLU()\n"," ),\n"," Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1)),\n"," ReLU(),\n"," Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1)),\n"," ReLU(),\n"," Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# model1 = nn.Sequential([nn.Linear(1,1),\n","#                        nn.Linear(1,1)]) # 리스트를 넣으면 안돼요!\n","\n","model2 = nn.Sequential(nn.Linear(1,1),\n","                       nn.Linear(1,1))\n","\n","# print(*[1,2])\n","# print([1,2])\n","\n","# model3 = nn.Sequential(*[nn.Linear(1,1),\n","#                          nn.Linear(1,1)])"],"metadata":{"id":"oc8lzg4XfnU_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = VGG(cfgs[\"E\"], batch_norm=True)\n","# print(model)\n","!pip install torchinfo\n","from torchinfo import summary\n","summary(model, input_size=(2,3,224,224), device='cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvG7IvI5jHpD","executionInfo":{"status":"ok","timestamp":1763991364462,"user_tz":-540,"elapsed":9208,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"b078222a-8918-44f5-e505-84868e15208c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]},{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","VGG                                      [2, 1000]                 --\n","├─Sequential: 1-1                        [2, 512, 7, 7]            --\n","│    └─Conv2d: 2-1                       [2, 64, 224, 224]         1,728\n","│    └─BatchNorm2d: 2-2                  [2, 64, 224, 224]         128\n","│    └─ReLU: 2-3                         [2, 64, 224, 224]         --\n","│    └─Conv2d: 2-4                       [2, 64, 224, 224]         36,864\n","│    └─BatchNorm2d: 2-5                  [2, 64, 224, 224]         128\n","│    └─ReLU: 2-6                         [2, 64, 224, 224]         --\n","│    └─MaxPool2d: 2-7                    [2, 64, 112, 112]         --\n","│    └─Conv2d: 2-8                       [2, 128, 112, 112]        73,728\n","│    └─BatchNorm2d: 2-9                  [2, 128, 112, 112]        256\n","│    └─ReLU: 2-10                        [2, 128, 112, 112]        --\n","│    └─Conv2d: 2-11                      [2, 128, 112, 112]        147,456\n","│    └─BatchNorm2d: 2-12                 [2, 128, 112, 112]        256\n","│    └─ReLU: 2-13                        [2, 128, 112, 112]        --\n","│    └─MaxPool2d: 2-14                   [2, 128, 56, 56]          --\n","│    └─Conv2d: 2-15                      [2, 256, 56, 56]          294,912\n","│    └─BatchNorm2d: 2-16                 [2, 256, 56, 56]          512\n","│    └─ReLU: 2-17                        [2, 256, 56, 56]          --\n","│    └─Conv2d: 2-18                      [2, 256, 56, 56]          589,824\n","│    └─BatchNorm2d: 2-19                 [2, 256, 56, 56]          512\n","│    └─ReLU: 2-20                        [2, 256, 56, 56]          --\n","│    └─Conv2d: 2-21                      [2, 256, 56, 56]          589,824\n","│    └─BatchNorm2d: 2-22                 [2, 256, 56, 56]          512\n","│    └─ReLU: 2-23                        [2, 256, 56, 56]          --\n","│    └─Conv2d: 2-24                      [2, 256, 56, 56]          589,824\n","│    └─BatchNorm2d: 2-25                 [2, 256, 56, 56]          512\n","│    └─ReLU: 2-26                        [2, 256, 56, 56]          --\n","│    └─MaxPool2d: 2-27                   [2, 256, 28, 28]          --\n","│    └─Conv2d: 2-28                      [2, 512, 28, 28]          1,179,648\n","│    └─BatchNorm2d: 2-29                 [2, 512, 28, 28]          1,024\n","│    └─ReLU: 2-30                        [2, 512, 28, 28]          --\n","│    └─Conv2d: 2-31                      [2, 512, 28, 28]          2,359,296\n","│    └─BatchNorm2d: 2-32                 [2, 512, 28, 28]          1,024\n","│    └─ReLU: 2-33                        [2, 512, 28, 28]          --\n","│    └─Conv2d: 2-34                      [2, 512, 28, 28]          2,359,296\n","│    └─BatchNorm2d: 2-35                 [2, 512, 28, 28]          1,024\n","│    └─ReLU: 2-36                        [2, 512, 28, 28]          --\n","│    └─Conv2d: 2-37                      [2, 512, 28, 28]          2,359,296\n","│    └─BatchNorm2d: 2-38                 [2, 512, 28, 28]          1,024\n","│    └─ReLU: 2-39                        [2, 512, 28, 28]          --\n","│    └─MaxPool2d: 2-40                   [2, 512, 14, 14]          --\n","│    └─Conv2d: 2-41                      [2, 512, 14, 14]          2,359,296\n","│    └─BatchNorm2d: 2-42                 [2, 512, 14, 14]          1,024\n","│    └─ReLU: 2-43                        [2, 512, 14, 14]          --\n","│    └─Conv2d: 2-44                      [2, 512, 14, 14]          2,359,296\n","│    └─BatchNorm2d: 2-45                 [2, 512, 14, 14]          1,024\n","│    └─ReLU: 2-46                        [2, 512, 14, 14]          --\n","│    └─Conv2d: 2-47                      [2, 512, 14, 14]          2,359,296\n","│    └─BatchNorm2d: 2-48                 [2, 512, 14, 14]          1,024\n","│    └─ReLU: 2-49                        [2, 512, 14, 14]          --\n","│    └─Conv2d: 2-50                      [2, 512, 14, 14]          2,359,296\n","│    └─BatchNorm2d: 2-51                 [2, 512, 14, 14]          1,024\n","│    └─ReLU: 2-52                        [2, 512, 14, 14]          --\n","│    └─MaxPool2d: 2-53                   [2, 512, 7, 7]            --\n","├─AdaptiveAvgPool2d: 1-2                 [2, 512, 7, 7]            --\n","├─Sequential: 1-3                        [2, 1000]                 --\n","│    └─Linear: 2-54                      [2, 4096]                 102,764,544\n","│    └─ReLU: 2-55                        [2, 4096]                 --\n","│    └─Dropout: 2-56                     [2, 4096]                 --\n","│    └─Linear: 2-57                      [2, 4096]                 16,781,312\n","│    └─ReLU: 2-58                        [2, 4096]                 --\n","│    └─Dropout: 2-59                     [2, 4096]                 --\n","│    └─Linear: 2-60                      [2, 1000]                 4,097,000\n","==========================================================================================\n","Total params: 143,672,744\n","Trainable params: 143,672,744\n","Non-trainable params: 0\n","Total mult-adds (Units.GIGABYTES): 39.26\n","==========================================================================================\n","Input size (MB): 1.20\n","Forward/backward pass size (MB): 475.41\n","Params size (MB): 574.69\n","Estimated Total Size (MB): 1051.31\n","=========================================================================================="]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["x = torch.randn(2,3,224,224)\n","print(model(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kRIMzNHikwjp","executionInfo":{"status":"ok","timestamp":1763991389402,"user_tz":-540,"elapsed":2436,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"904264db-9a0f-4192-b536-32033315546f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1000])\n"]}]},{"cell_type":"code","source":["x = torch.randn(2,3,300,300)\n","print(model(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1vA8PYXffDbX","executionInfo":{"status":"ok","timestamp":1763991409767,"user_tz":-540,"elapsed":2793,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"383f930a-c39c-4df3-9f53-333be8752e82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1000])\n"]}]},{"cell_type":"code","source":["x = torch.randn(2,3,32,32)\n","print(model(x).shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BodeeTqUfFfO","executionInfo":{"status":"ok","timestamp":1763991505959,"user_tz":-540,"elapsed":157,"user":{"displayName":"ppen hyuk","userId":"06590780498642875598"}},"outputId":"9cdf28d0-63a5-4d50-bc33-5a3b121b4be1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 1000])\n"]}]},{"cell_type":"code","source":["# nn.MaxPool2d(2)(torch.randn(2,3,1,1)) # error!"],"metadata":{"id":"0VrNRTa0mnqk"},"execution_count":null,"outputs":[]}]}