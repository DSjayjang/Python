{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbdd32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0d53512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.872983346207417"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# euclidean\n",
    "u1 = np.array([4, 1, 1, 4])\n",
    "u3 = np.array([2, 0, 4,5 ])\n",
    "\n",
    "euc_sim = np.sqrt(np.sum((u1 - u3)**2))\n",
    "euc_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732b63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.666666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean squared Difference (MSD)\n",
    "# euclidean에서 null 값을 제거한 것들끼리의 유사도\n",
    "\n",
    "u1 = np.array([4, 1, 1, 4])\n",
    "u3 = np.array([2, 0, 4, 5])\n",
    "\n",
    "MSD = (2**2+ 3**2+ 1**2)/3\n",
    "MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e5e62672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JMSD\n",
    "u1 = np.array([4, 1, 1, 4])\n",
    "u1_norm = u1/5\n",
    "\n",
    "u3 = np.array([2, 0, 4, 5])\n",
    "u3_norm = u3/5\n",
    "\n",
    "jcd = 3/4\n",
    "MSD = ((u1_norm[0] - u3_norm[0])**2 + (u1_norm[2] - u3_norm[2])**2 + (u1_norm[3] - u3_norm[3])**2)/3\n",
    "\n",
    "JMSD = jcd * (1-MSD)\n",
    "JMSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "914b99bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9399999999999998"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cosine\n",
    "u1 = np.array([5, 4, 3])\n",
    "u3 = np.array([3, 5, 4])\n",
    "\n",
    "# cos_sim = np.sum((u1 * u3))/(np.sqrt(np.sum(u1**2)) * np.sqrt(np.sum((u3**2))))\n",
    "cos_sim = np.sum((u1 * u3))/(np.linalg.norm(u1, ord = 2) * np.linalg.norm(u3, ord = 2))\n",
    "\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d93152e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.17817416127494962"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pearson correlation coefficient (PCC)\n",
    "u1 = np.array([4, 1, 1, 4])\n",
    "u3 = np.array([2,    4, 5])\n",
    "\n",
    "u1_mean = np.mean(u1)\n",
    "u3_mean = np.mean(u3)\n",
    "\n",
    "new_u1 = np.array([4, 1, 4])\n",
    "new_u3 = np.array([2, 4, 5])\n",
    "\n",
    "a = new_u1-u1_mean\n",
    "b = new_u3-u3_mean\n",
    "\n",
    "pcc = np.sum(a*b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "pcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "735921b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2581988897471611"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constrained Pearson\n",
    "u1 = np.array([4, 1, 1, 4])\n",
    "u3 = np.array([2,    4, 5])\n",
    "\n",
    "u1_med = np.median(u1)\n",
    "u3_med = np.median(u3)\n",
    "\n",
    "new_u1 = np.array([4, 1, 4])\n",
    "new_u3 = np.array([2, 4, 5])\n",
    "\n",
    "a = new_u1-u1_med\n",
    "b = new_u3-u3_med\n",
    "\n",
    "pcc = np.sum(a*b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "pcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ddfd9",
   "metadata": {},
   "source": [
    "# Predicting rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65a2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b5859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6803, -0.4092, -0.4208,  2.5337, -0.5688],\n",
      "        [-0.5046, -0.2327,  0.1694,  1.2958,  0.0040],\n",
      "        [-0.6674,  0.5148,  0.2724,  0.7052,  0.2956],\n",
      "        [-0.4160, -0.8628, -0.3162,  0.2292, -0.2077],\n",
      "        [ 0.3218, -0.4759,  1.9482, -0.6812,  0.3304]])\n",
      "tensor([[0.8429, 0.3991, 0.3963, 0.9265, 0.3615],\n",
      "        [0.3765, 0.4421, 0.5422, 0.7851, 0.5010],\n",
      "        [0.3391, 0.6259, 0.5677, 0.6693, 0.5734],\n",
      "        [0.3975, 0.2967, 0.4216, 0.5570, 0.4483],\n",
      "        [0.5798, 0.3832, 0.8753, 0.3360, 0.5819]])\n",
      "tensor([[0.2703, 0.0335, 0.0331, 0.6346, 0.0285],\n",
      "        [0.0834, 0.1095, 0.1636, 0.5048, 0.1387],\n",
      "        [0.0747, 0.2436, 0.1912, 0.2947, 0.1957],\n",
      "        [0.1700, 0.1087, 0.1878, 0.3241, 0.2094],\n",
      "        [0.1264, 0.0569, 0.6428, 0.0464, 0.1275]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(5,5)\n",
    "print(a)\n",
    "print(torch.sigmoid(a))\n",
    "\n",
    "b=torch.softmax(a, dim=-1)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "743220a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998999999999999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.0425, 0.0349, 0.0409, 0.0401, 0.0512, 0.0434, 0.0353, 0.0382, 0.0407,\n",
    "         0.0641, 0.0427, 0.0420, 0.0449, 0.0415, 0.0452, 0.0444, 0.0425, 0.0410,\n",
    "         0.0445, 0.0419, 0.0377, 0.0578, 0.0425]\n",
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "762757f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[9.96086014e-04 1.40002958e-04 6.53129869e-05 ... 8.67607086e-04\n",
      "   1.89510673e-05 7.77334808e-04]\n",
      "  [1.20792449e-03 1.24203174e-03 1.37730703e-04 ... 1.16115137e-03\n",
      "   3.22658977e-04 1.23653129e-03]\n",
      "  [1.27422929e-03 2.95993543e-05 2.19334323e-04 ... 4.96792581e-05\n",
      "   2.39761530e-05 1.38970771e-04]\n",
      "  [5.02671928e-04 8.09809775e-04 2.86705408e-04 ... 8.37966111e-04\n",
      "   3.90332985e-04 1.20886060e-03]\n",
      "  [5.81566608e-04 1.23801236e-03 8.63581442e-04 ... 8.87684332e-04\n",
      "   6.28903503e-04 6.43869022e-04]]\n",
      "\n",
      " [[8.14144972e-04 6.70689662e-04 1.80271645e-04 ... 2.23350775e-04\n",
      "   6.10940092e-04 4.99922657e-04]\n",
      "  [9.05418413e-04 2.34268882e-04 1.32305265e-03 ... 8.53180921e-04\n",
      "   1.04459944e-03 2.07302534e-04]\n",
      "  [5.98402304e-04 8.72521888e-04 5.05045961e-04 ... 7.84226175e-04\n",
      "   1.78361746e-04 3.75681459e-04]\n",
      "  [1.28040257e-03 1.16917109e-03 6.62470770e-05 ... 2.37887255e-04\n",
      "   1.14842629e-03 1.31609026e-03]\n",
      "  [3.80767470e-04 1.10537499e-03 7.38960107e-04 ... 3.73055239e-04\n",
      "   8.82357814e-04 6.50084973e-04]]\n",
      "\n",
      " [[2.53061382e-04 1.17017949e-03 3.07952786e-05 ... 1.03254301e-03\n",
      "   3.21009243e-04 1.37329951e-04]\n",
      "  [1.00494147e-03 1.24909516e-03 1.24414671e-03 ... 3.44877401e-04\n",
      "   1.25085415e-03 1.25960574e-03]\n",
      "  [3.78402290e-04 6.66385431e-04 2.45819558e-04 ... 6.65353295e-04\n",
      "   2.34431123e-04 5.98495917e-04]\n",
      "  [9.01984392e-04 1.20217436e-03 1.25368893e-04 ... 1.01824357e-03\n",
      "   1.31461743e-03 8.75353652e-05]\n",
      "  [4.29336700e-04 5.67995585e-04 1.03635277e-03 ... 2.76698462e-04\n",
      "   6.02648647e-04 1.09512765e-03]]\n",
      "\n",
      " [[3.41589346e-04 6.67599011e-04 2.37574165e-04 ... 1.22563571e-03\n",
      "   6.79384948e-04 3.64274754e-04]\n",
      "  [5.76826038e-04 2.29043190e-05 9.68423156e-04 ... 1.26459567e-03\n",
      "   9.16557674e-04 1.26432151e-03]\n",
      "  [3.03278172e-04 8.08040552e-04 1.20577499e-03 ... 8.18547992e-04\n",
      "   4.57989274e-04 1.19062529e-03]\n",
      "  [1.26974802e-04 1.05035513e-03 1.30974682e-03 ... 2.93982468e-04\n",
      "   1.06934837e-03 7.97901697e-04]\n",
      "  [9.68647696e-04 8.42722152e-04 9.78018263e-04 ... 1.29635787e-04\n",
      "   6.99627393e-04 4.78176126e-04]]]\n",
      "L_sparse_h: [1. 1. 1. 1.]\n",
      "L_sparse: 1.0\n"
     ]
    }
   ],
   "source": [
    "# L1 norm\n",
    "# 정규화하면 항상 상수\n",
    "# np.random.seed(0)\n",
    "\n",
    "# attention map\n",
    "H, N, T = 4, 5, 300\n",
    "A = np.random.rand(H, N, T)\n",
    "\n",
    "# 각 헤드 attention map 합\n",
    "A_sum = A.sum(axis=(1,2), keepdims=True) # (H, 1, 1)\n",
    "\n",
    "# normalization\n",
    "A_tilde = A / A_sum # (H, N, T)\n",
    "\n",
    "# 각 헤드 L_sparse\n",
    "L_sparse_h = np.sum(np.abs(A_tilde), axis=(1,2)) # (H, )\n",
    "print(np.abs(A_tilde))\n",
    "print('L_sparse_h:', L_sparse_h)\n",
    "\n",
    "# L_sparse\n",
    "L_sparse = np.sum(L_sparse_h) / H\n",
    "print('L_sparse:', L_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45ee0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sparse_h: [751.61065834 761.10900491 730.89206559 734.63562859]\n",
      "L_sparse: 744.5618393542486\n"
     ]
    }
   ],
   "source": [
    "# L1 norm\n",
    "# 정규화안하면? 너무 큼;\n",
    "np.random.seed(0)\n",
    "\n",
    "# attention map\n",
    "H, N, T = 4, 5, 300\n",
    "A = np.random.rand(H, N, T)\n",
    "\n",
    "# # 각 헤드 attention map 합\n",
    "# A_sum = A.sum(axis=(1,2), keepdims=True) # (H, 1, 1)\n",
    "\n",
    "# # normalization\n",
    "# A_tilde = A / A_sum # (H, N, T)\n",
    "\n",
    "# 각 헤드 L_sparse\n",
    "L_sparse_h = np.sum(np.abs(A), axis=(1,2)) # (H, )\n",
    "print('L_sparse_h:', L_sparse_h)\n",
    "\n",
    "# L_sparse\n",
    "L_sparse = np.sum(L_sparse_h) / H\n",
    "print('L_sparse:', L_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e86381a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sparse_h: [0.02994695 0.02973857 0.02990276 0.02994167]\n",
      "L_sparse: 0.02988248741742505\n"
     ]
    }
   ],
   "source": [
    "# L2 norm\n",
    "# 클수록 sparse? 따라서 loss는 마이너스\n",
    "np.random.seed(0)\n",
    "\n",
    "# attention map\n",
    "H, N, T = 4, 5, 300\n",
    "A = np.random.rand(H, N, T)\n",
    "\n",
    "# 각 헤드 attention map 합\n",
    "A_sum = A.sum(axis=(1,2), keepdims=True) # (H, 1, 1)\n",
    "\n",
    "# normalization\n",
    "A_tilde = A / A_sum # (H, N, T)\n",
    "\n",
    "# 각 헤드 L_sparse\n",
    "L_sparse_h = np.sqrt(np.sum(A_tilde**2, axis=(1,2))) # (H, )\n",
    "print('L_sparse_h:', L_sparse_h)\n",
    "\n",
    "# L_sparse\n",
    "L_sparse = np.sum(L_sparse_h) / H\n",
    "print('L_sparse:', L_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "59c95249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sparse_h: [7.11137899 7.13174637 7.1210385  7.11569716]\n",
      "L_sparse: 7.119965256725331\n"
     ]
    }
   ],
   "source": [
    "# entropy\n",
    "# np.random.seed(0)\n",
    "\n",
    "# attention map\n",
    "H, N, T = 4, 5, 300\n",
    "A = np.random.rand(H, N, T)\n",
    "\n",
    "# 각 헤드 attention map 합\n",
    "A_sum = A.sum(axis=(1,2), keepdims=True) # (H, 1, 1)\n",
    "\n",
    "# normalization\n",
    "A_tilde = A / A_sum # (H, N, T)\n",
    "\n",
    "# entropy\n",
    "eps = 1e-12\n",
    "ent_h = -np.sum(A_tilde * np.log(A_tilde+eps), axis=(1,2))\n",
    "\n",
    "# 각 헤드 L_sparse\n",
    "L_sparse_h = ent_h\n",
    "print('L_sparse_h:', L_sparse_h)\n",
    "\n",
    "# L_sparse\n",
    "L_sparse = np.sum(L_sparse_h) / H\n",
    "print('L_sparse:', L_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec703a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "log(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ent_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(A_tilde \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_tilde\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m, dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      2\u001b[0m ent_h\n",
      "\u001b[1;31mTypeError\u001b[0m: log(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7087450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00089682, -0.00088438, -0.00089418, -0.0008965 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_sparse_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e40737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sparse_h: tensor([[6.9057, 6.8923, 6.8965, 6.9063],\n",
      "        [6.8951, 6.9125, 6.9044, 6.9081],\n",
      "        [6.8915, 6.8820, 6.8944, 6.8934],\n",
      "        [6.8963, 6.9046, 6.9045, 6.8902],\n",
      "        [6.9051, 6.9067, 6.8933, 6.9208],\n",
      "        [6.9002, 6.9028, 6.8940, 6.8972],\n",
      "        [6.8902, 6.9010, 6.8886, 6.9130],\n",
      "        [6.8912, 6.8819, 6.8911, 6.8909]], grad_fn=<NegBackward0>)\n",
      "L_sparse: tensor(6.8983, grad_fn=<MeanBackward0>)\n",
      "L_sparse=6.898311614990\n",
      "tensor(6.6281, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MultiHeadSparsityLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the multi-head sparsity regularization:\n",
    "        For each head h, A^{(h)} ∈ R^{N×T} is normalized by its sum,\n",
    "        then L_sparse^{(h)} = ||Â^{(h)}||_1, and\n",
    "        L_sparse = (1/H) * sum_h L_sparse^{(h)}.\n",
    "    Supports input shapes (B,H,N,T) or (B,N,T). Optionally supports a mask over frames.\n",
    "    \"\"\"\n",
    "    def __init__(self, eps: float = 1e-12, reduction: str = \"mean\"):\n",
    "        \"\"\"\n",
    "        eps: small constant to avoid division by zero\n",
    "        reduction: 'mean' (default), 'sum', or 'none' over the batch\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        assert reduction in (\"mean\", \"sum\", \"none\")\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, A: torch.Tensor, frame_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args\n",
    "        ----\n",
    "        A : torch.Tensor\n",
    "            Attention maps with shape (B,H,N,T) or (B,N,T).\n",
    "        frame_mask : torch.Tensor, optional\n",
    "            Valid-frame mask of shape (B,T) or (B,1,T). Ones for valid frames, zeros for padded frames.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : torch.Tensor\n",
    "            Scalar loss if reduction != 'none', else (B,) vector.\n",
    "        \"\"\"\n",
    "        if A.ndim == 3:\n",
    "            # (B,N,T) -> add H=1\n",
    "            A = A.unsqueeze(1)  # (B,1,N,T)\n",
    "        elif A.ndim != 4:\n",
    "            raise ValueError(\"A must be (B,H,N,T) or (B,N,T).\")\n",
    "\n",
    "        B, H, N, T = A.shape\n",
    "\n",
    "        # Optionally apply frame mask before normalization (mask invalid frames to zero)\n",
    "        if frame_mask is not None:\n",
    "            if frame_mask.ndim == 2:\n",
    "                frame_mask = frame_mask.unsqueeze(1)  # (B,1,T)\n",
    "            if frame_mask.ndim == 3:\n",
    "                # Broadcast to (B,1,1,T)\n",
    "                frame_mask = frame_mask.unsqueeze(1) if frame_mask.shape[1] != 1 else frame_mask\n",
    "            # reshape to (B,1,1,T) for broadcast over heads and joints\n",
    "            frame_mask = frame_mask.view(B, 1, 1, T)\n",
    "            A = A * frame_mask  # zero-out invalid frames\n",
    "\n",
    "        # Head-wise normalization by total sum over (N,T) so that sum_i,t Â^{(h)}_{i,t} = 1\n",
    "        sums = A.sum(dim=(2, 3), keepdim=True).clamp_min(self.eps)  # (B,H,1,1)\n",
    "        A_tilde = A / sums  # (B,H,N,T)\n",
    "\n",
    "        # L1 per head: ||Â^{(h)}||_1 = sum_{i,t} |Â^{(h)}_{i,t}|\n",
    "        # A_tilde >= 0 assumed (attention weights). If not guaranteed, abs() is safe.\n",
    "        # L_sparse_h = A_tilde.abs().sum(dim=(2, 3))  # (B,H)\n",
    "\n",
    "        # L_sparse_h = -torch.sqrt(torch.sum(A_tilde ** 2, dim = (2,3))) + self.eps\n",
    "        # L_sparse_h = -torch.sum(A_tilde ** 2, dim = (2,3))\n",
    "\n",
    "        # # 여기만;;\n",
    "        # # L1 per head: ||Â^{(h)}||_1 = sum_{i,t} |Â^{(h)}_{i,t}|\n",
    "        # # A_tilde >= 0 assumed (attention weights). If not guaranteed, abs() is safe.\n",
    "        # L_sparse_h = A.abs().sum(dim=(2, 3))  # (B,H)\n",
    "\n",
    "        ent_h = -torch.sum(A_tilde * torch.log(A_tilde+eps), dim=(-1,-2))\n",
    "        ent_h\n",
    "        L_sparse_h = ent_h\n",
    "        print('L_sparse_h:', L_sparse_h)\n",
    "        # Average over heads: (1/H) * sum_h L_sparse^{(h)}\n",
    "        L_sparse = L_sparse_h.mean(dim=1)  # (B,)\n",
    "\n",
    "        if self.reduction == \"mean\":\n",
    "            return L_sparse.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return L_sparse.sum()\n",
    "        else:  # 'none'\n",
    "            return L_sparse  # (B,)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 사용 예시\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    B, H, N, T = 8, 4, 25, 48\n",
    "    A = torch.rand(B, H, N, T, requires_grad=True)  # 예시 attention\n",
    "    y = torch.randint(0, 300, (B,))                 # 예시 라벨\n",
    "    logits = torch.randn(B, 300, requires_grad=True)\n",
    "\n",
    "    # 손실들\n",
    "    ce = nn.CrossEntropyLoss()(logits, y)\n",
    "\n",
    "    sparse_loss_fn = MultiHeadSparsityLoss(eps=1e-12, reduction=\"mean\")\n",
    "    L_sparse = sparse_loss_fn(A)  # \\mathcal{L}_{sparse}\n",
    "\n",
    "    # 가중합 (예: lambda_s = 0.1)\n",
    "    lambda_s = 0.1\n",
    "    loss = ce + lambda_s * L_sparse\n",
    "    loss.backward()\n",
    "\n",
    "    print('L_sparse:', L_sparse)\n",
    "    print(f\"L_sparse={L_sparse.item():.12f}\")\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea0f49a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identity()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e74820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\Anaconda\\envs\\chem2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c450fa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(g):\n",
    "    with g.local_scope():\n",
    "        g.edata['h'] = torch.ones((g.num_edges(), 3))\n",
    "        g.edata['h2'] = torch.ones((g.num_edges(), 3))\n",
    "        return g.edata['h']\n",
    "g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
    "g.edata['h'] = torch.zeros((g.num_edges(), 3))\n",
    "newh = foo(g)\n",
    "print(g.edata['h'])  # still get tensor of all zeros\n",
    "'h2' in g.edata      # new feature set in the function scope is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "494089e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "def foo(g):\n",
    "    with g.local_scope():\n",
    "        # in-place operation\n",
    "        g.edata['h'] += 1\n",
    "        return g.edata['h']\n",
    "g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
    "g.edata['h'] = torch.zeros((g.num_edges(), 1))\n",
    "newh = foo(g)\n",
    "print(g.edata['h'])  # the result changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6144507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = dgl.graph((torch.tensor([0, 1, 1]), torch.tensor([0, 0, 2])))\n",
    "g.num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a3c105",
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Expect number of features to match number of edges. Got 4 and 3 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      2\u001b[0m g\n",
      "File \u001b[1;32mc:\\Programming\\Anaconda\\envs\\chem2\\lib\\site-packages\\dgl\\view.py:227\u001b[0m, in \u001b[0;36mHeteroEdgeDataView.__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, (\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe HeteroEdgeDataView has only one edge type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease pass a tensor directly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    226\u001b[0m     )\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_e_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_etid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Anaconda\\envs\\chem2\\lib\\site-packages\\dgl\\heterograph.py:4457\u001b[0m, in \u001b[0;36mDGLGraph._set_e_repr\u001b[1;34m(self, etid, edges, data)\u001b[0m\n\u001b[0;32m   4455\u001b[0m nfeats \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mshape(val)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   4456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nfeats \u001b[38;5;241m!=\u001b[39m num_edges:\n\u001b[1;32m-> 4457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\n\u001b[0;32m   4458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpect number of features to match number of edges.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (nfeats, num_edges)\n\u001b[0;32m   4460\u001b[0m     )\n\u001b[0;32m   4461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcontext(val) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[0;32m   4462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\n\u001b[0;32m   4463\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot assign edge feature \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m on device \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to a graph on\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   4464\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m device \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Call DGLGraph.to() to copy the graph to the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4465\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m same device.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key, F\u001b[38;5;241m.\u001b[39mcontext(val), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   4466\u001b[0m     )\n",
      "\u001b[1;31mDGLError\u001b[0m: Expect number of features to match number of edges. Got 4 and 3 instead."
     ]
    }
   ],
   "source": [
    "g.edata['h'] = torch.ones((4, 5))\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b16adbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.tensor([0, 0, 1, 2])  # 0->1, 0->2, 1->0, 2->0\n",
    "dst = torch.tensor([1, 2, 0, 0])\n",
    "g = dgl.graph((src, dst), num_nodes=3)\n",
    "g.num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d011c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self loop 추가\n",
    "g = dgl.add_self_loop(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e08285db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_nodes: 3\n",
      "num_edges: 7\n",
      "edges (src->dst): (tensor([0, 0, 1, 2, 0, 1, 2]), tensor([1, 2, 0, 0, 0, 1, 2]))\n"
     ]
    }
   ],
   "source": [
    "print(\"num_nodes:\", g.num_nodes())\n",
    "print(\"num_edges:\", g.num_edges())\n",
    "print(\"edges (src->dst):\", g.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73ebb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node feature\n",
    "x = torch.tensor([\n",
    "    [0., 1.],  # node 0 = O\n",
    "    [1., 0.],  # node 1 = H\n",
    "    [1., 0.],  # node 2 = H\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cde8f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output y:\n",
      "tensor([[-0.7681, -0.1208,  0.1879, -0.2347],\n",
      "        [-0.6043, -0.2150,  0.1336, -0.2604],\n",
      "        [-0.6043, -0.2150,  0.1336, -0.2604]], grad_fn=<AddmmBackward0>)\n",
      "y.shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "\n",
    "# -------------------------\n",
    "# Your modules 그대로\n",
    "# -------------------------\n",
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(dim_in, dim_out)\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        return {'h': h}\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.msg = fn.copy_u('h', 'm')\n",
    "        self.apply_mod = NodeApplyModule(dim_in, dim_out)\n",
    "\n",
    "    def reduce(self, nodes):\n",
    "        mbox = nodes.mailbox['m']      # (num_nodes, num_in_edges, dim_in)\n",
    "        accum = torch.mean(mbox, dim=1)\n",
    "        return {'h': accum}\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        # forward마다 graph에 임시 feature를 넣으니 local_scope 권장\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = feature\n",
    "            g.update_all(self.msg, self.reduce)\n",
    "            g.apply_nodes(func=self.apply_mod)\n",
    "            return g.ndata['h']\n",
    "        \n",
    "        torch.manual_seed(0)      # Linear 초기화 재현용\n",
    "layer = GCNLayer(dim_in=2, dim_out=4)\n",
    "\n",
    "y = layer(g, x)\n",
    "    \n",
    "print(\"\\nOutput y:\")\n",
    "print(y)                  # (3, 4)\n",
    "print(\"y.shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e753bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import dgl\n",
    "from dgl.nn import GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b884d938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9533, -0.0866],\n",
       "        [ 0.9533, -0.0866],\n",
       "        [ 1.0751, -0.0977],\n",
       "        [ 1.2046, -0.1095],\n",
       "        [ 0.8518, -0.0774],\n",
       "        [ 0.8518, -0.0774]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3]))\n",
    "g = dgl.to_bidirected(g)\n",
    "g = dgl.add_self_loop(g)\n",
    "g.num_nodes()\n",
    "feat = torch.ones(6, 10)\n",
    "conv = GraphConv(10, 2, norm='both', weight = True, bias = False)\n",
    "res = conv(g, feat)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "af1ab89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1657, -0.3529],\n",
       "        [ 1.1657, -0.3529],\n",
       "        [ 1.3146, -0.3980],\n",
       "        [ 1.4729, -0.4459],\n",
       "        [ 1.0415, -0.3153],\n",
       "        [ 1.0415, -0.3153]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3]))\n",
    "g = dgl.to_bidirected(g)\n",
    "g = dgl.add_self_loop(g)\n",
    "g.num_nodes()\n",
    "feat = torch.ones(6, 10)\n",
    "conv = GraphConv(10, 2, norm='both', weight = True, bias = False)\n",
    "res = conv(g, feat)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "362f9d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 1.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tilde = g.adj().to_dense()\n",
    "A_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88b28090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2541, -0.4789],\n",
       "        [ 1.3808, -0.5273],\n",
       "        [ 1.2541, -0.4789],\n",
       "        [ 1.5876, -0.6063],\n",
       "        [ 1.6667, -0.6365],\n",
       "        [ 0.9763, -0.3729]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = g.adj().to_dense()  # 보통 A[src, dst]=1 형태로 생각하면 됨\n",
    "\n",
    "deg_out = g.out_degrees().float()\n",
    "deg_in  = g.in_degrees().float()\n",
    "\n",
    "Dout_inv_sqrt = torch.diag(torch.pow(deg_out, -0.5))\n",
    "Din_inv_sqrt  = torch.diag(torch.pow(deg_in,  -0.5))\n",
    "\n",
    "# GraphConv: Din^-1/2 * A^T * Dout^-1/2 * X * W\n",
    "res2 = Din_inv_sqrt @ A.T @ Dout_inv_sqrt @ feat @ conv.weight\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6ad6da1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1657, -0.3529],\n",
       "        [ 1.1657, -0.3529],\n",
       "        [ 1.3146, -0.3980],\n",
       "        [ 1.4729, -0.4459],\n",
       "        [ 1.0415, -0.3153],\n",
       "        [ 1.0415, -0.3153]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tilde = g.adj().to_dense()\n",
    "deg = A_tilde.sum(dim=1)\n",
    "D_tilde = torch.diag(deg)\n",
    "D_tilde2 = torch.diag(torch.pow(deg, -1/2))\n",
    "res2 = D_tilde2 @ A_tilde @ D_tilde2 @ feat @ conv.weight\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ca2e26a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1657, -0.3529],\n",
       "        [ 1.1657, -0.3529],\n",
       "        [ 1.3146, -0.3980],\n",
       "        [ 1.4729, -0.4459],\n",
       "        [ 1.0415, -0.3153],\n",
       "        [ 1.0415, -0.3153]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_tilde = g.adj().to_dense()\n",
    "deg = A_tilde.sum(dim=1)\n",
    "D_tilde = torch.pow(deg, -0.5)\n",
    "\n",
    "X1 = feat * D_tilde.unsqueeze(-1)\n",
    "X2 = A_tilde @ X1\n",
    "X3 = X2 * D_tilde.unsqueeze(-1)\n",
    "res3 = X3 @ conv.weight\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea06d343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0408, -0.1750],\n",
      "        [ 0.0449, -0.1926],\n",
      "        [ 0.0408, -0.1750],\n",
      "        [ 0.0517, -0.2215],\n",
      "        [ 0.0542, -0.2325],\n",
      "        [ 0.0318, -0.1362]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.6709, -0.9603],\n",
      "        [-0.9488, -1.3581],\n",
      "        [-0.9488, -1.3581],\n",
      "        [-1.1453, -1.6394],\n",
      "        [-0.9488, -1.3581],\n",
      "        [ 0.0000,  0.0000]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Case 1: Homogeneous graph\n",
    "g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3]))\n",
    "g = dgl.add_self_loop(g)\n",
    "feat = th.ones(6, 10)\n",
    "conv = GraphConv(10, 2, norm='both', weight=True, bias=True)\n",
    "res = conv(g, feat)\n",
    "print(res)\n",
    "# allow_zero_in_degree example\n",
    "g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3]))\n",
    "conv = GraphConv(10, 2, norm='both', weight=True, bias=True, allow_zero_in_degree=True)\n",
    "res = conv(g, feat)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28ff84a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1472, -0.3450],\n",
       "        [-0.0460, -0.3972],\n",
       "        [ 0.0715, -0.5248],\n",
       "        [ 0.1472, -0.3450]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case 2: Unidirectional bipartite graph\n",
    "u = [0, 1, 0, 0, 1]\n",
    "v = [0, 1, 2, 3, 2]\n",
    "g = dgl.heterograph({('_U', '_E', '_V') : (u, v)})\n",
    "u_fea = th.rand(2, 5)\n",
    "v_fea = th.rand(4, 5)\n",
    "conv = GraphConv(5, 2, norm='both', weight=True, bias=True)\n",
    "res = conv(g, (u_fea, v_fea))\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ce563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69ca6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d929115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES: CCO\n",
      "num_nodes: 3 num_edges: 7\n",
      "max|res - res2| = 2.9802322387695312e-08\n",
      "res[0]: tensor([-0.2014, -0.0164,  0.2904,  0.4515,  0.1802,  0.0613,  0.3045, -0.2674])\n",
      "res2[0]: tensor([-0.2014, -0.0164,  0.2904,  0.4515,  0.1802,  0.0613,  0.3045, -0.2674])\n",
      "res3[0]: tensor([-0.2014, -0.0164,  0.2904,  0.4515,  0.1802,  0.0613,  0.3045, -0.2674])\n",
      "max|res2 - res3| = 2.9802322387695312e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import dgl\n",
    "from rdkit import Chem\n",
    "from dgl.nn import GraphConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def adj_mat_to_edges(adj_mat):\n",
    "    edges = []\n",
    "    for i in range(adj_mat.shape[0]):\n",
    "        for j in range(adj_mat.shape[1]):\n",
    "            if adj_mat[i, j] == 1:\n",
    "                edges.append((i, j))\n",
    "    return edges\n",
    "\n",
    "def smiles_to_mol_graph_simple(smiles, feat_dim=16):\n",
    "    \"\"\"\n",
    "    네 코드 흐름과 동일:\n",
    "    RDKit adjacency -> edges -> DGLGraph + ndata['feat']\n",
    "    단, props 대신 간단 one-hot feature 사용\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    adj_mat = Chem.GetAdjacencyMatrix(mol)  # (N,N), 대칭(무방향)\n",
    "\n",
    "    edges = adj_mat_to_edges(adj_mat)\n",
    "    src, dst = tuple(zip(*edges)) if len(edges) > 0 else ([], [])\n",
    "\n",
    "    g = dgl.graph((torch.tensor(src), torch.tensor(dst)), num_nodes=adj_mat.shape[0]).to(device)\n",
    "\n",
    "    # --- node features (간단 예시): atomic number mod feat_dim one-hot ---\n",
    "    N = mol.GetNumAtoms()\n",
    "    X = torch.zeros((N, feat_dim), dtype=torch.float32, device=device)\n",
    "    for i, atom in enumerate(mol.GetAtoms()):\n",
    "        idx = atom.GetAtomicNum() % feat_dim\n",
    "        X[i, idx] = 1.0\n",
    "    g.ndata[\"feat\"] = X\n",
    "    return mol, g\n",
    "\n",
    "def check_match_with_paper(smiles=\"CCO\", out_dim=8):\n",
    "    mol, g = smiles_to_mol_graph_simple(smiles, feat_dim=16)\n",
    "    g = dgl.add_self_loop(g)  # 논문식 A~ = A + I\n",
    "\n",
    "    X = g.ndata[\"feat\"]  # (N, Fin)\n",
    "\n",
    "    # ---- DGL GraphConv ----\n",
    "    torch.manual_seed(0)\n",
    "    conv = GraphConv(X.shape[1], out_dim, norm=\"both\", weight=True, bias=False).to(device)\n",
    "\n",
    "    res = conv(g, X)  # (N, out_dim)\n",
    "\n",
    "    # ---- 논문식 행렬곱: D~^-1/2 A~ D~^-1/2 X W ----\n",
    "    # g는 이미 무방향(양방향 edge) + self-loop 상태라 A~는 대칭이어야 함\n",
    "    A_tilde = g.adj().to_dense()  # (N,N), 보통 float\n",
    "    deg = A_tilde.sum(dim=1)      # D~_ii = sum_j A~_ij (row-sum)\n",
    "    D_inv_sqrt = torch.diag(torch.pow(deg, -0.5))\n",
    "    # Kipf 식 (활성화 σ는 생략: GraphConv도 activation 안 넣으면 동일하게 비교 가능)\n",
    "    res2 = D_inv_sqrt @ A_tilde @ D_inv_sqrt @ X @ conv.weight\n",
    "\n",
    "    D_inv_sqrt2 = torch.pow(deg, -0.5)\n",
    "    X1 = X * D_inv_sqrt2.unsqueeze(-1)\n",
    "    X2 = A_tilde @ X1\n",
    "    X3 = X2 * D_inv_sqrt2.unsqueeze(-1)\n",
    "    res3 = X3 @ conv.weight\n",
    "\n",
    "    # ---- 비교 ----\n",
    "    diff = (res - res2).abs().max().item()\n",
    "    diff2 = (res2 - res3).abs().max().item()\n",
    "    print(\"SMILES:\", smiles)\n",
    "    print(\"num_nodes:\", g.num_nodes(), \"num_edges:\", g.num_edges())\n",
    "    print(\"max|res - res2| =\", diff)\n",
    "    print(\"res[0]:\", res[0].detach().cpu())\n",
    "    print(\"res2[0]:\", res2[0].detach().cpu())\n",
    "    print(\"res3[0]:\", res3[0].detach().cpu())\n",
    "    print(\"max|res2 - res3| =\", diff2)\n",
    "\n",
    "check_match_with_paper(\"CCO\", out_dim=8)   # 에탄올 예시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1e5b945b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 4., 4., 2., 2.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deg.clamp_min(0.0001)\n",
    "# deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a3914ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "DGLError",
     "evalue": "Expect number of features to match number of nodes (len(u)). Got 3 and 6 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     idx \u001b[38;5;241m=\u001b[39m atom\u001b[38;5;241m.\u001b[39mGetAtomicNum() \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m      6\u001b[0m     X[i, idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m X\n",
      "File \u001b[1;32mc:\\Programming\\Anaconda\\envs\\chem2\\lib\\site-packages\\dgl\\view.py:99\u001b[0m, in \u001b[0;36mHeteroNodeDataView.__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, (\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe HeteroNodeDataView has only one node type. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease pass a tensor directly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m     )\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_n_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ntid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Anaconda\\envs\\chem2\\lib\\site-packages\\dgl\\heterograph.py:4344\u001b[0m, in \u001b[0;36mDGLGraph._set_n_repr\u001b[1;34m(self, ntid, u, data)\u001b[0m\n\u001b[0;32m   4342\u001b[0m nfeats \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mshape(val)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   4343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nfeats \u001b[38;5;241m!=\u001b[39m num_nodes:\n\u001b[1;32m-> 4344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\n\u001b[0;32m   4345\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpect number of features to match number of nodes (len(u)).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4346\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (nfeats, num_nodes)\n\u001b[0;32m   4347\u001b[0m     )\n\u001b[0;32m   4348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcontext(val) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[0;32m   4349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DGLError(\n\u001b[0;32m   4350\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot assign node feature \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m on device \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to a graph on\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   4351\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m device \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. Call DGLGraph.to() to copy the graph to the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4352\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m same device.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key, F\u001b[38;5;241m.\u001b[39mcontext(val), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   4353\u001b[0m     )\n",
      "\u001b[1;31mDGLError\u001b[0m: Expect number of features to match number of nodes (len(u)). Got 3 and 6 instead."
     ]
    }
   ],
   "source": [
    "mol = Chem.MolFromSmiles('COO')\n",
    "N = mol.GetNumAtoms()\n",
    "X = torch.zeros((N, 16), dtype=torch.float32, device=device)\n",
    "for i, atom in enumerate(mol.GetAtoms()):\n",
    "    idx = atom.GetAtomicNum() % 16\n",
    "    X[i, idx] = 1.0\n",
    "g.ndata[\"feat\"] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "966131ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6\n",
      "1 6\n",
      "2 8\n"
     ]
    }
   ],
   "source": [
    "mol = Chem.MolFromSmiles('CCO')\n",
    "N = mol.GetNumAtoms()\n",
    "for i, atom in enumerate(mol.GetAtoms()):\n",
    "    print(i, atom.GetAtomicNum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5dfb1621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5214, 0.9105],\n",
       "        [0.5214, 0.9105],\n",
       "        [0.5880, 1.0268],\n",
       "        [0.6588, 1.1505],\n",
       "        [0.4659, 0.8135],\n",
       "        [0.4659, 0.8135]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3]))\n",
    "# g = dgl.to_bidirected(g) # 방향 > 무방향으로 엣지 추가\n",
    "# g = dgl.add_self_loop(g)\n",
    "# feat = torch.ones(6, 10)\n",
    "\n",
    "A_tilde = g.adj().to_dense()\n",
    "deg = A_tilde.sum(dim=1)\n",
    "D_tilde = torch.pow(deg, -0.5)\n",
    "\n",
    "X1 = feat * D_tilde.unsqueeze(-1)\n",
    "X2 = A_tilde @ X1\n",
    "X3 = X2 * D_tilde.unsqueeze(-1)\n",
    "res3 = X3 @ conv.weight\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "20d45327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5214, 0.9105],\n",
       "        [0.5214, 0.9105],\n",
       "        [0.5880, 1.0268],\n",
       "        [0.6588, 1.1505],\n",
       "        [0.4659, 0.8135],\n",
       "        [0.4659, 0.8135]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "A_tilde = g.adj().to_dense()\n",
    "deg = A_tilde.sum(dim=1)\n",
    "D_tilde = torch.diag(deg)\n",
    "D_tilde2 = torch.diag(torch.pow(deg, -1/2))\n",
    "res2 = D_tilde2 @ A_tilde @ D_tilde2 @ feat @ conv.weight\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "73c9e914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5214, 0.9105],\n",
       "        [0.5214, 0.9105],\n",
       "        [0.5880, 1.0268],\n",
       "        [0.6588, 1.1505],\n",
       "        [0.4659, 0.8135],\n",
       "        [0.4659, 0.8135]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = GraphConv(10, 2, norm='both', weight = True, bias = False)\n",
    "res = conv(g, feat)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb11208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f9cf0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape: torch.Size([1, 2, 1, 4])\n",
      "A before mask:\n",
      " tensor([[[[0.1000, 0.2000, 0.3000, 0.4000]],\n",
      "\n",
      "         [[1.1000, 1.2000, 1.3000, 1.4000]]]])\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 설정\n",
    "# -------------------------\n",
    "B, H, N, T = 1, 2, 1, 4\n",
    "\n",
    "# Attention map A : (B, H, N, T)\n",
    "A = torch.tensor(\n",
    "    [[\n",
    "        # head 0\n",
    "        [[0.1, 0.2, 0.3, 0.4]],\n",
    "\n",
    "        # head 1\n",
    "        [[1.1, 1.2, 1.3, 1.4]],\n",
    "    ]]\n",
    ")\n",
    "\n",
    "print(\"A shape:\", A.shape)\n",
    "print(\"A before mask:\\n\", A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e33b586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1000, 0.2000, 0.3000, 0.4000, 1.1000, 1.2000, 1.3000, 1.4000]]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.view(B,1,1,T*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4aa1d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "frame_mask shape: torch.Size([1, 1, 1, 4])\n",
      "frame_mask:\n",
      " tensor([[[[1, 1, 0, 1]]]])\n"
     ]
    }
   ],
   "source": [
    "# frame_mask : (B, 1, 1, T)\n",
    "# t=2 프레임만 invalid (0)\n",
    "frame_mask = torch.tensor([[[[1, 1, 0, 1]]]])\n",
    "\n",
    "print(\"\\nframe_mask shape:\", frame_mask.shape)\n",
    "print(\"frame_mask:\\n\", frame_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c440ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 1, 0, 1]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_mask.view(1,1,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c43454cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.7000, 1.1000],\n",
       "        [1.3000, 1.7000, 2.1000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a873a030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A after mask:\n",
      " tensor([[[[0.1000, 0.2000, 0.0000, 0.4000],\n",
      "          [0.5000, 0.6000, 0.0000, 0.8000],\n",
      "          [0.9000, 1.0000, 0.0000, 1.2000]],\n",
      "\n",
      "         [[1.1000, 1.2000, 0.0000, 1.4000],\n",
      "          [1.5000, 1.6000, 0.0000, 1.8000],\n",
      "          [1.9000, 2.0000, 0.0000, 2.2000]]]])\n"
     ]
    }
   ],
   "source": [
    "A_masked = A * frame_mask\n",
    "print(\"\\nA after mask:\\n\", A_masked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "837ce4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.7000, 1.1000],\n",
       "        [1.3000, 1.7000, 2.1000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "685dd753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_masked[0, :, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2473c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSparsityLoss(nn.Module):\n",
    "    def __init__(self, eps: float = 1e-12, reduction: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        assert reduction in (\"mean\", \"sum\", \"none\")\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, A: torch.Tensor, frame_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        if A.ndim == 3:\n",
    "            A = A.unsqueeze(1) # (B,N,T) -> (B,1,N,T)\n",
    "        elif A.ndim != 4:\n",
    "            raise ValueError(\"A must be (B,H,N,T) or (B,N,T).\")\n",
    "\n",
    "        B, H, N, T = A.shape\n",
    "\n",
    "        # frame_mask: allow (B,T), (B,1,T), (B,1,1,T)\n",
    "        if frame_mask is not None:\n",
    "            if frame_mask.ndim == 2:          # (B,T)\n",
    "                frame_mask = frame_mask[:, None, None, :]     # (B,1,1,T)\n",
    "            elif frame_mask.ndim == 3:        # (B,1,T)\n",
    "                frame_mask = frame_mask[:, None, :, :]        # (B,1,1,T) if middle dim==1\n",
    "                if frame_mask.shape[2] != 1:\n",
    "                    raise ValueError(\"frame_mask with ndim=3 must be (B,1,T).\")\n",
    "            elif frame_mask.ndim == 4:        # (B,1,1,T)\n",
    "                if frame_mask.shape[1:3] != (1,1):\n",
    "                    raise ValueError(\"frame_mask with ndim=4 must be (B,1,1,T).\")\n",
    "            else:\n",
    "                raise ValueError(\"frame_mask must be (B,T), (B,1,T), or (B,1,1,T).\")\n",
    "\n",
    "            frame_mask = frame_mask.view(B, 1, 1, T)\n",
    "            A = A * frame_mask  # zero-out invalid frames\n",
    "\n",
    "        # Head-wise normalization by total sum over (N,T)\n",
    "        sums = A.sum(dim=(2, 3), keepdim=True).clamp_min(self.eps) # (B,H,1,1)\n",
    "        A_tilde = A / sums # (B,H,N,T)\n",
    "\n",
    "        # Entropy\n",
    "        L_sparse_h = -torch.sum(A_tilde * torch.log(A_tilde+self.eps), axis=(2,3))\n",
    "        print('L_sparse_h:', L_sparse_h.shape)\n",
    "\n",
    "        # Average over heads\n",
    "        L_sparse = L_sparse_h.mean(dim=1) # (B,)\n",
    "        print(L_sparse)\n",
    "        if self.reduction == \"mean\":\n",
    "            return L_sparse.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return L_sparse.sum()\n",
    "        else:\n",
    "            return L_sparse  # (B,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f3851113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_sparse_h: torch.Size([8, 4])\n",
      "tensor([6.8965, 6.9004, 6.9001, 6.8937, 6.8916, 6.8958, 6.8991, 6.8901],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "L_sparse: tensor(6.8959, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadSparsityLoss(nn.Module):\n",
    "    def __init__(self, eps: float = 1e-12, reduction: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        assert reduction in (\"mean\", \"sum\", \"none\")\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, A: torch.Tensor, frame_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        if A.ndim == 3:\n",
    "            A = A.unsqueeze(1) # (B,N,T) -> (B,1,N,T)\n",
    "        elif A.ndim != 4:\n",
    "            raise ValueError(\"A must be (B,H,N,T) or (B,N,T).\")\n",
    "\n",
    "        B, H, N, T = A.shape\n",
    "\n",
    "        # frame_mask: allow (B,T), (B,1,T), (B,1,1,T)\n",
    "        if frame_mask is not None:\n",
    "            if frame_mask.ndim == 2:          # (B,T)\n",
    "                frame_mask = frame_mask[:, None, None, :]     # (B,1,1,T)\n",
    "            elif frame_mask.ndim == 3:        # (B,1,T)\n",
    "                frame_mask = frame_mask[:, None, :, :]        # (B,1,1,T) if middle dim==1\n",
    "                if frame_mask.shape[2] != 1:\n",
    "                    raise ValueError(\"frame_mask with ndim=3 must be (B,1,T).\")\n",
    "            elif frame_mask.ndim == 4:        # (B,1,1,T)\n",
    "                if frame_mask.shape[1:3] != (1,1):\n",
    "                    raise ValueError(\"frame_mask with ndim=4 must be (B,1,1,T).\")\n",
    "            else:\n",
    "                raise ValueError(\"frame_mask must be (B,T), (B,1,T), or (B,1,1,T).\")\n",
    "\n",
    "            frame_mask = frame_mask.view(B, 1, 1, T)\n",
    "            A = A * frame_mask  # zero-out invalid frames\n",
    "\n",
    "        # Head-wise normalization by total sum over (N,T)\n",
    "        sums = A.sum(dim=(2, 3), keepdim=True).clamp_min(self.eps) # (B,H,1,1)\n",
    "        A_tilde = A / sums # (B,H,N,T)\n",
    "\n",
    "        # Entropy\n",
    "        L_sparse_h = -torch.sum(A_tilde * torch.log(A_tilde+self.eps), axis=(2,3))\n",
    "        print('L_sparse_h:', L_sparse_h.shape)\n",
    "\n",
    "        # Average over heads\n",
    "        L_sparse = L_sparse_h.mean(dim=1) # (B,)\n",
    "        print(L_sparse)\n",
    "        if self.reduction == \"mean\":\n",
    "            return L_sparse.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return L_sparse.sum()\n",
    "        else:\n",
    "            return L_sparse  # (B,)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 사용 예시\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    B, H, N, T = 8, 4, 25, 48\n",
    "    A = torch.rand(B, H, N, T, requires_grad=True)  # 예시 attention\n",
    "    y = torch.randint(0, 300, (B,))                 # 예시 라벨\n",
    "    logits = torch.randn(B, 300, requires_grad=True)\n",
    "\n",
    "    # 손실들\n",
    "    ce = nn.CrossEntropyLoss()(logits, y)\n",
    "\n",
    "    sparse_loss_fn = MultiHeadSparsityLoss(eps=1e-12, reduction=\"mean\")\n",
    "    L_sparse = sparse_loss_fn(A)  # \\mathcal{L}_{sparse}\n",
    "\n",
    "    # 가중합 (예: lambda_s = 0.1)\n",
    "    lambda_s = 0.1\n",
    "    loss = ce + lambda_s * L_sparse\n",
    "    loss.backward()\n",
    "\n",
    "    print('L_sparse:', L_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3b73c2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadDiversityLoss(nn.Module):\n",
    "    def __init__(self, eps: float = 1e-12, reduction: str = \"mean\"):\n",
    "        super().__init__()\n",
    "        assert reduction in (\"mean\", \"sum\", \"none\")\n",
    "        self.eps = eps\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, A: torch.Tensor, frame_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        if A.ndim == 3:\n",
    "            A = A.unsqueeze(1) # (B,N,T) -> (B,1,N,T)\n",
    "        elif A.ndim != 4:\n",
    "            raise ValueError(\"A must be (B,H,N,T) or (B,N,T).\")\n",
    "\n",
    "        B, H, N, T = A.shape\n",
    "\n",
    "        # frame_mask: allow (B,T), (B,1,T), (B,1,1,T)\n",
    "        if frame_mask is not None:\n",
    "            if frame_mask.ndim == 2:          # (B,T)\n",
    "                frame_mask = frame_mask[:, None, None, :]     # (B,1,1,T)\n",
    "            elif frame_mask.ndim == 3:        # (B,1,T)\n",
    "                if frame_mask.shape[2] != 1:\n",
    "                    raise ValueError(\"frame_mask with ndim=3 must be (B,1,T).\")\n",
    "                frame_mask = frame_mask[:, None, :, :]        # (B,1,1,T) if middle dim==1\n",
    "            elif frame_mask.ndim == 4:        # (B,1,1,T)\n",
    "                if frame_mask.shape[1:3] != (1,1):\n",
    "                    raise ValueError(\"frame_mask with ndim=4 must be (B,1,1,T).\")\n",
    "            else:\n",
    "                raise ValueError(\"frame_mask must be (B,T), (B,1,T), or (B,1,1,T).\")\n",
    "\n",
    "            frame_mask = frame_mask.view(B, 1, 1, T)\n",
    "            A = A * frame_mask  # zero-out invalid frames\n",
    "\n",
    "        # Head-wise normalization by total sum over (N,T)\n",
    "        sums = A.sum(dim=(2, 3), keepdim=True).clamp_min(self.eps) # (B,H,1,1)\n",
    "        A_tilde = A / sums # (B,H,N,T)\n",
    "\n",
    "        # Vectorize per head\n",
    "        A_vec = A_tilde.reshape(B, H, N*T)\n",
    "\n",
    "        # L2-normalize per head vector\n",
    "        A_hat = F.normalize(A_vec, dim=2, eps=self.eps) # (B,H,NT)\n",
    "\n",
    "        # If H == 1, no pair exists -> loss = 0\n",
    "        if H <= 1:\n",
    "            zero = A_hat.new_zeros(B)\n",
    "            if self.reduction == \"mean\":\n",
    "                return zero.mean()\n",
    "            elif self.reduction == \"sum\":\n",
    "                return zero.sum()\n",
    "            else:\n",
    "                return zero  # (B,)\n",
    "\n",
    "        # squared cosine similarity\n",
    "        G = torch.bmm(A_hat, A_hat.transpose(1, 2)) # (B,H,H)\n",
    "        G2 = G.pow(2)                                        \n",
    "\n",
    "        triu_mask = torch.triu(torch.ones(H, H, dtype=torch.bool, device=A_hat.device), diagonal=1)\n",
    "        pair_sums = G2[:, triu_mask].sum(dim=1) # (B,)\n",
    "\n",
    "        L_div_per_sample = (2.0 / (H * (H - 1))) * pair_sums # (B,)\n",
    "\n",
    "        # Reduction over batch\n",
    "        if self.reduction == \"mean\":\n",
    "            return L_div_per_sample.mean()\n",
    "        elif self.reduction == \"sum\":\n",
    "            return L_div_per_sample.sum()\n",
    "        else:\n",
    "            return L_div_per_sample  # (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "42bed714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.6615, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    B, H, N, T = 8, 4, 25, 48\n",
    "    # 예시 attention (이미 head-wise 정규화된 형태를 권장하지만, 아래 구현은 L2정규화도 적용)\n",
    "    A = torch.rand(B, H, N, T, requires_grad=True)\n",
    "\n",
    "    # diversity loss\n",
    "    div_loss_fn = MultiHeadDiversityLoss()\n",
    "    L_div = div_loss_fn(A)  # \\mathcal{L}_{div}\n",
    "\n",
    "    # 다른 손실과 결합 예시\n",
    "    logits = torch.randn(B, 300, requires_grad=True)\n",
    "    y = torch.randint(0, 300, (B,))\n",
    "    ce = nn.CrossEntropyLoss()(logits, y)\n",
    "\n",
    "    lambda_div = 0.05\n",
    "    loss = ce + lambda_div * L_div\n",
    "    loss.backward()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "62c54cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True,  True],\n",
      "        [False, False,  True],\n",
      "        [False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "H = 3\n",
    "triu_mask = torch.triu(\n",
    "    torch.ones(H, H, dtype=torch.bool),\n",
    "    diagonal=1\n",
    ")\n",
    "\n",
    "print(triu_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2d6a2151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G2 shape: torch.Size([1, 3, 3])\n",
      "tensor([[[1.0000, 0.2000, 0.3000],\n",
      "         [0.2000, 1.0000, 0.4000],\n",
      "         [0.3000, 0.4000, 1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# 배치 1개, H=3\n",
    "G2 = torch.tensor([[\n",
    "    [1.00, 0.20, 0.30],\n",
    "    [0.20, 1.00, 0.40],\n",
    "    [0.30, 0.40, 1.00]\n",
    "]])\n",
    "\n",
    "print(\"G2 shape:\", G2.shape)\n",
    "print(G2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "21ae6539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2000, 0.3000, 0.4000]])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "selected = G2[:, triu_mask]\n",
    "print(selected)\n",
    "print(selected.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "09718dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.2000, 0.3000],\n",
       "         [0.2000, 1.0000, 0.4000],\n",
       "         [0.3000, 0.4000, 1.0000]]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G2[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f871c0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5000, 1.6000, 1.7000]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G2[:,].sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a818b294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input descriptor shape: torch.Size([2, 5])\n",
      "Value embedding shape: torch.Size([2, 5, 4])\n",
      "ID embedding shape: torch.Size([2, 5, 4])\n",
      "Token shape: torch.Size([2, 5, 4])\n",
      "\n",
      "Descriptor[0] value embedding:\n",
      "tensor([[-0.3926,  0.8046, -0.8429,  0.0570],\n",
      "        [-0.4001,  1.3410, -1.6659, -0.6790],\n",
      "        [-0.4076,  1.8775, -2.4889, -1.4149],\n",
      "        [-0.4151,  2.4139, -3.3120, -2.1509],\n",
      "        [-0.4226,  2.9504, -4.1350, -2.8868]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "Descriptor ID embedding:\n",
      "tensor([[-0.3561,  0.4372,  0.4913, -0.2041],\n",
      "        [ 0.1665,  0.8744, -0.1435, -0.1116],\n",
      "        [-0.6136,  0.0316, -0.4927,  0.2484],\n",
      "        [ 0.6181, -0.4128, -0.8411, -2.3160],\n",
      "        [-0.1023,  0.7924, -0.2897,  0.0525]], grad_fn=<SelectBackward0>)\n",
      "\n",
      "Final token = value + ID:\n",
      "tensor([[-0.7488,  1.2418, -0.3516, -0.1472],\n",
      "        [-0.2337,  2.2154, -1.8094, -0.7906],\n",
      "        [-1.0212,  1.9091, -2.9816, -1.1665],\n",
      "        [ 0.2030,  2.0011, -4.1531, -4.4669],\n",
      "        [-0.5249,  3.7428, -4.4247, -2.8343]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# -----------------------------\n",
    "# Descriptor Tokenizer 정의\n",
    "# -----------------------------\n",
    "class Descriptor_Tokenizer(nn.Module):\n",
    "    def __init__(self, d_desc: int, d_t: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.val_embedding = nn.Linear(1, d_t)\n",
    "        self.id_embedding = nn.Embedding(d_desc, d_t)\n",
    "\n",
    "        self.num_desc = d_desc\n",
    "        self.d_t = d_t\n",
    "\n",
    "    def forward(self, descriptor: torch.Tensor):\n",
    "        B, D = descriptor.shape\n",
    "\n",
    "        # value embedding\n",
    "        desc = descriptor.unsqueeze(-1)        # (B, D) -> (B, D, 1)\n",
    "        val_emb = self.val_embedding(desc)     # (B, D, d_t)\n",
    "\n",
    "        # ID embedding\n",
    "        ids = torch.arange(D, device=descriptor.device)\n",
    "        id_emb = self.id_embedding(ids)        # (D, d_t)\n",
    "        id_emb = id_emb.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "        desc_tks = val_emb + id_emb\n",
    "\n",
    "        return desc_tks, val_emb, id_emb\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 테스트 실행\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    B = 2     # batch size (분자 2개)\n",
    "    D = 5     # descriptor 개수\n",
    "    d_t = 4   # token dimension\n",
    "\n",
    "    tokenizer = Descriptor_Tokenizer(d_desc=D, d_t=d_t)\n",
    "\n",
    "    # 예시 descriptor 입력\n",
    "    desc = torch.tensor([\n",
    "        [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "        [5.0, 4.0, 3.0, 2.0, 1.0],\n",
    "    ])\n",
    "\n",
    "    tokens, val_emb, id_emb = tokenizer(desc)\n",
    "\n",
    "    print(\"Input descriptor shape:\", desc.shape)\n",
    "    print(\"Value embedding shape:\", val_emb.shape)\n",
    "    print(\"ID embedding shape:\", id_emb.shape)\n",
    "    print(\"Token shape:\", tokens.shape)\n",
    "\n",
    "    print(\"\\nDescriptor[0] value embedding:\")\n",
    "    print(val_emb[0])\n",
    "\n",
    "    print(\"\\nDescriptor ID embedding:\")\n",
    "    print(id_emb[0])\n",
    "\n",
    "    print(\"\\nFinal token = value + ID:\")\n",
    "    print(tokens[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc0ceae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Embedding(5,4 )\n",
    "idx = torch.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4961da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "        [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "        [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "        [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "        [-1.1057,  0.1437,  0.5836,  1.3482]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53759a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.arange(5)\n",
    "id_emb = a(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4f8d0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]],\n",
       "\n",
       "        [[ 0.5851, -1.1560, -0.1434, -0.1947],\n",
       "         [-0.9069, -0.5918,  0.1508, -1.0411],\n",
       "         [-0.7205, -2.2148, -0.6837,  0.5164],\n",
       "         [ 0.7928,  0.0832,  0.4228, -1.8687],\n",
       "         [-1.1057,  0.1437,  0.5836,  1.3482]]], grad_fn=<ExpandBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_emb.unsqueeze(0).expand(32,-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a13f6a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m val_embedding  \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mval_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Anaconda\\envs\\chem2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\Anaconda\\envs\\chem2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\Anaconda\\envs\\chem2\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not int"
     ]
    }
   ],
   "source": [
    "val_embedding  = nn.Linear(1, 4)\n",
    "val_embedding(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234334e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptor shape: torch.Size([5, 3])\n",
      "Value embedding: torch.Size([5, 3, 4])\n",
      "ID embedding: torch.Size([5, 3, 4])\n",
      "Final tokens: torch.Size([5, 3, 4])\n",
      "\n",
      "Descriptor input:\n",
      "tensor([[1.0000, 2.0000, 3.0000],\n",
      "        [3.0000, 2.0000, 1.0000],\n",
      "        [4.0000, 5.0000, 6.0000],\n",
      "        [6.0000, 5.0000, 4.0000],\n",
      "        [1.5000, 2.5000, 3.5000]])\n",
      "\n",
      "Value embedding (분자마다 다름):\n",
      "tensor([[[-0.3926,  0.8046, -0.8429,  0.0570],\n",
      "         [-0.4001,  1.3410, -1.6659, -0.6790],\n",
      "         [-0.4076,  1.8775, -2.4889, -1.4149]],\n",
      "\n",
      "        [[-0.4076,  1.8775, -2.4889, -1.4149],\n",
      "         [-0.4001,  1.3410, -1.6659, -0.6790],\n",
      "         [-0.3926,  0.8046, -0.8429,  0.0570]],\n",
      "\n",
      "        [[-0.4151,  2.4139, -3.3120, -2.1509],\n",
      "         [-0.4226,  2.9504, -4.1350, -2.8868],\n",
      "         [-0.4301,  3.4868, -4.9581, -3.6227]],\n",
      "\n",
      "        [[-0.4301,  3.4868, -4.9581, -3.6227],\n",
      "         [-0.4226,  2.9504, -4.1350, -2.8868],\n",
      "         [-0.4151,  2.4139, -3.3120, -2.1509]],\n",
      "\n",
      "        [[-0.3964,  1.0728, -1.2544, -0.3110],\n",
      "         [-0.4039,  1.6093, -2.0774, -1.0470],\n",
      "         [-0.4114,  2.1457, -2.9005, -1.7829]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "ID embedding (batch마다 동일):\n",
      "tensor([[[-1.0845, -1.3986,  0.4033,  0.8380],\n",
      "         [-0.7193, -0.4033, -0.5966,  0.1820],\n",
      "         [-0.8567,  1.1006, -1.0712,  0.1227]],\n",
      "\n",
      "        [[-1.0845, -1.3986,  0.4033,  0.8380],\n",
      "         [-0.7193, -0.4033, -0.5966,  0.1820],\n",
      "         [-0.8567,  1.1006, -1.0712,  0.1227]],\n",
      "\n",
      "        [[-1.0845, -1.3986,  0.4033,  0.8380],\n",
      "         [-0.7193, -0.4033, -0.5966,  0.1820],\n",
      "         [-0.8567,  1.1006, -1.0712,  0.1227]],\n",
      "\n",
      "        [[-1.0845, -1.3986,  0.4033,  0.8380],\n",
      "         [-0.7193, -0.4033, -0.5966,  0.1820],\n",
      "         [-0.8567,  1.1006, -1.0712,  0.1227]],\n",
      "\n",
      "        [[-1.0845, -1.3986,  0.4033,  0.8380],\n",
      "         [-0.7193, -0.4033, -0.5966,  0.1820],\n",
      "         [-0.8567,  1.1006, -1.0712,  0.1227]]], grad_fn=<ExpandBackward0>)\n",
      "\n",
      "Final tokens = value + ID:\n",
      "tensor([[[-1.4772, -0.5940, -0.4395,  0.8950],\n",
      "         [-1.1194,  0.9377, -2.2625, -0.4970],\n",
      "         [-1.2643,  2.9781, -3.5601, -1.2922]],\n",
      "\n",
      "        [[-1.4921,  0.4789, -2.0856, -0.5769],\n",
      "         [-1.1194,  0.9377, -2.2625, -0.4970],\n",
      "         [-1.2493,  1.9052, -1.9140,  0.1797]],\n",
      "\n",
      "        [[-1.4996,  1.0153, -2.9086, -1.3128],\n",
      "         [-1.1418,  2.5470, -4.7317, -2.7048],\n",
      "         [-1.2867,  4.5874, -6.0293, -3.5000]],\n",
      "\n",
      "        [[-1.5146,  2.0882, -4.5547, -2.7847],\n",
      "         [-1.1418,  2.5470, -4.7317, -2.7048],\n",
      "         [-1.2718,  3.5145, -4.3832, -2.0282]],\n",
      "\n",
      "        [[-1.4809, -0.3258, -0.8510,  0.5270],\n",
      "         [-1.1231,  1.2059, -2.6741, -0.8649],\n",
      "         [-1.2680,  3.2463, -3.9717, -1.6602]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# ----------------------------\n",
    "# Descriptor Tokenizer\n",
    "# ----------------------------\n",
    "class Descriptor_Tokenizer(nn.Module):\n",
    "    def __init__(self, d_desc: int, d_t: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # value embedding\n",
    "        self.val_embedding = nn.Linear(1, d_t)\n",
    "\n",
    "        # descriptor identity embedding\n",
    "        self.id_embedding = nn.Embedding(d_desc, d_t)\n",
    "\n",
    "    def forward(self, descriptor):\n",
    "        B, D = descriptor.shape\n",
    "\n",
    "        # value embedding\n",
    "        desc = descriptor.unsqueeze(-1)      # (B, D) -> (B, D, 1)\n",
    "        val_emb = self.val_embedding(desc)   # (B, D, d_t)\n",
    "\n",
    "        # ID embedding\n",
    "        ids = torch.arange(D) # (D, )\n",
    "        id_emb = self.id_embedding(ids)      # (D, d_t)\n",
    "        id_emb = id_emb.unsqueeze(0).expand(B, -1, -1)\n",
    "\n",
    "        tokens = val_emb + id_emb\n",
    "\n",
    "        return tokens, val_emb, id_emb\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 테스트 입력\n",
    "# ----------------------------\n",
    "B = 5   # 분자 개수\n",
    "D = 3   # descriptor 개수\n",
    "d_t = 4 # token dimension\n",
    "\n",
    "tokenizer = Descriptor_Tokenizer(d_desc=D, d_t=d_t)\n",
    "\n",
    "# (5,3) descriptor 예제\n",
    "descriptor = torch.tensor([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [3.0, 2.0, 1.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [6.0, 5.0, 4.0],\n",
    "    [1.5, 2.5, 3.5],\n",
    "])\n",
    "\n",
    "tokens, val_emb, id_emb = tokenizer(descriptor)\n",
    "\n",
    "print(\"Descriptor shape:\", descriptor.shape)\n",
    "print(\"Value embedding:\", val_emb.shape)\n",
    "print(\"ID embedding:\", id_emb.shape)\n",
    "print(\"Final tokens:\", tokens.shape)\n",
    "\n",
    "print(\"\\nDescriptor input:\")\n",
    "print(descriptor)\n",
    "\n",
    "print(\"\\nValue embedding (분자마다 다름):\")\n",
    "print(val_emb)\n",
    "\n",
    "print(\"\\nID embedding (batch마다 동일):\")\n",
    "print(id_emb)\n",
    "\n",
    "print(\"\\nFinal tokens = value + ID:\")\n",
    "print(tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chem2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
