{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f03e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "080417b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0895, -0.1527, -0.5851],\n",
      "        [-0.5845, -0.4716, -0.5187],\n",
      "        [-2.0829, -1.8987, -0.2065]])\n",
      "tensor([[0.4309, 0.2573, 0.2111],\n",
      "        [0.2830, 0.9468, 0.3256],\n",
      "        [0.5520, 0.5918, 0.9177]])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(3,3) # Normal 의 n\n",
    "B = torch.rand(3,3) # 이건 uniform\n",
    "\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "590a5a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2., -1., -2.],\n",
       "        [ 0., -1., -1.],\n",
       "        [ 1.,  1.,  0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.floor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7440c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1172, -0.7585,  0.5978],\n",
      "        [ 0.7320,  0.0827, -0.6457],\n",
      "        [-0.9274,  0.5196, -0.1786]])\n",
      "tensor([[0.1172, 0.7585, 0.5978],\n",
      "        [0.7320, 0.0827, 0.6457],\n",
      "        [0.9274, 0.5196, 0.1786]])\n"
     ]
    }
   ],
   "source": [
    "# torch.abs()\n",
    "A = torch.randn(3, 3)\n",
    "\n",
    "print(A)\n",
    "print(torch.abs(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6568c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8412, -1.1415,  0.3658],\n",
      "        [ 1.4939, -1.1553,  0.2184],\n",
      "        [ 1.4429,  1.2290, -0.5289]])\n",
      "tensor([[0.9172, 1.0684, 0.6048],\n",
      "        [1.2223, 1.0748, 0.4674],\n",
      "        [1.2012, 1.1086, 0.7272]])\n"
     ]
    }
   ],
   "source": [
    "# torch.sqrt()\n",
    "A = torch.randn(3, 3)\n",
    "\n",
    "print(A)\n",
    "print(torch.sqrt(torch.abs(A)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94f135c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9844,  0.2728,  0.1605],\n",
      "        [-1.6301,  0.2603, -1.9631],\n",
      "        [-0.0500,  0.8533,  1.1820]])\n",
      "tensor([[2.6763, 1.3136, 1.1742],\n",
      "        [0.1959, 1.2973, 0.1404],\n",
      "        [0.9513, 2.3474, 3.2609]])\n"
     ]
    }
   ],
   "source": [
    "# torch.exp()\n",
    "A = torch.randn(3, 3)\n",
    "\n",
    "print(A)\n",
    "print(torch.exp(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fbe47d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5399, -0.1466,  0.8977],\n",
      "        [-1.5797, -0.7181,  1.2293],\n",
      "        [ 1.4188,  1.6415,  0.1050]])\n",
      "tensor([[-0.6163, -1.9202, -0.1079],\n",
      "        [ 0.4572, -0.3311,  0.2065],\n",
      "        [ 0.3498,  0.4956, -2.2540]])\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# torch.log()\n",
    "A = torch.randn(3, 3)\n",
    "\n",
    "print(A)\n",
    "print(torch.log(torch.abs(A)))\n",
    "print(torch.log(torch.exp(torch.tensor(1))))\n",
    "#print(torch.log(torch.exp(1))) # error\n",
    "\n",
    "print(torch.log10(torch.tensor(10)))\n",
    "print(torch.log2(torch.tensor(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8456c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8339, -0.1697, -0.2437],\n",
      "        [ 0.7478,  1.8171,  0.9521],\n",
      "        [ 0.8335, -0.3031,  1.0360]])\n",
      "tensor([[-1., -0., -0.],\n",
      "        [ 1.,  2.,  1.],\n",
      "        [ 1., -0.,  1.]])\n",
      "tensor([[-0.8300, -0.1700, -0.2400],\n",
      "        [ 0.7500,  1.8200,  0.9500],\n",
      "        [ 0.8300, -0.3000,  1.0400]])\n",
      "tensor([[-1., -1., -1.],\n",
      "        [ 0.,  1.,  0.],\n",
      "        [ 0., -1.,  1.]])\n",
      "tensor([[-0., -0., -0.],\n",
      "        [1., 2., 1.],\n",
      "        [1., -0., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.round() / torch.floor() / torch.ceil()\n",
    "A = torch.randn(3, 3)\n",
    "\n",
    "print(A)\n",
    "print(torch.round(A))\n",
    "print(torch.round(A, decimals = 2)) # 소수점 둘째자리까지\n",
    "\n",
    "print(torch.floor(A))\n",
    "print(torch.ceil(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42d0b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n",
      "tensor(0.5000)\n",
      "tensor(1.)\n",
      "tensor(-1.)\n",
      "<class 'float'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# torch.sin() / torch.cos() / torch.tan() / torch.tanh()\n",
    "print(torch.sin(torch.tensor(torch.pi/6))) # sin 30도\n",
    "print(torch.cos(torch.tensor(torch.pi/3))) # cos 60도\n",
    "print(torch.tan(torch.tensor(torch.pi/4))) # tan 45도\n",
    "\n",
    "print(torch.tanh(torch.tensor(-10)))\n",
    "\n",
    "# torch.pi는 float이라서 tensor로 변경해줘야 사용 가능\n",
    "print(type(torch.pi))\n",
    "print(type(torch.tensor(torch.pi/6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bdb275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "tensor(nan)\n",
      "tensor([False, False,  True, False, False])\n",
      "tensor([False, False, False, False,  True])\n"
     ]
    }
   ],
   "source": [
    "# torch.nan / torch.isnan() / torch.isinf()\n",
    "print(torch.nan) # not a number\n",
    "\n",
    "print(torch.log(torch.tensor(-1)))\n",
    "print(torch.isnan(torch.tensor([1, 2, torch.nan, 3, 4])))\n",
    "print(torch.isinf(torch.tensor([1, 2, 3, 4, torch.inf])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de5ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1458, -0.5573, -1.5921, -1.0514],\n",
      "        [-0.5857,  0.6137, -0.7344, -1.3591],\n",
      "        [-0.9215,  0.3135,  0.5613,  0.8570]])\n",
      "tensor(0.8570)\n",
      "torch.return_types.max(\n",
      "values=tensor([-0.5857,  0.6137,  0.5613,  0.8570]),\n",
      "indices=tensor([1, 1, 2, 2]))\n",
      "torch.return_types.max(\n",
      "values=tensor([-0.5573,  0.6137,  0.8570]),\n",
      "indices=tensor([1, 1, 3]))\n",
      "torch.return_types.max(\n",
      "values=tensor([[-0.5857,  0.6137,  0.5613,  0.8570]]),\n",
      "indices=tensor([[1, 1, 2, 2]]))\n",
      "torch.return_types.max(\n",
      "values=tensor([[-0.5573],\n",
      "        [ 0.6137],\n",
      "        [ 0.8570]]),\n",
      "indices=tensor([[1],\n",
      "        [1],\n",
      "        [3]]))\n"
     ]
    }
   ],
   "source": [
    "# torch.max()\n",
    "A = torch.randn(3,4)\n",
    "print(A)\n",
    "\n",
    "# 3x4 중 가장 큰 값\n",
    "print(torch.max(A)) \n",
    "\n",
    "# 0번째 dimension 방향으로 각각 가장 큰 값.\n",
    "# 즉, 4개의 값이 나옴\n",
    "print(torch.max(A, dim = 0))\n",
    "\n",
    "# 1번째 dimension 방향으로 각각 가장 큰 값.\n",
    "# 즉, 3개의 값이 나옴\n",
    "print(torch.max(A, dim = 1)) \n",
    "\n",
    "# 0번째 dimension 방향으로 각각 가장 큰 값.\n",
    "# 그리고 dimension은 유지\n",
    "print(torch.max(A, dim = 0, keepdim = True)) \n",
    "\n",
    "# 1번째 dimension 방향으로 각각 가장 큰 값.\n",
    "# 그리고 dimension은 유지.\n",
    "# 즉, 3x1 짜리 2D tensor\n",
    "print(torch.max(A, dim = 1, keepdim = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24535a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2271, -0.8179,  1.3430,  0.3997],\n",
      "        [ 0.1429,  0.3335,  0.0851, -1.7514],\n",
      "        [ 1.9710, -1.3510,  1.1681, -0.3809]])\n",
      "tensor(8)\n",
      "tensor([2, 1, 0, 0])\n",
      "tensor([2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# torch.argmax()\n",
    "A = torch.randn(3,4)\n",
    "print(A)\n",
    "\n",
    "print(torch.argmax(A))\n",
    "\n",
    "# 각 열에서 가장 큰 값이 존재하는 인덱스\n",
    "print(torch.argmax(A,dim=0))\n",
    "\n",
    "# 각 행에서 가장 큰 값이 존재하는 인덱스\n",
    "print(torch.argmax(A,dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80cac30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8518],\n",
      "        [ 0.9623],\n",
      "        [-0.7140],\n",
      "        [ 1.4051],\n",
      "        [-1.3720],\n",
      "        [-0.2899]])\n",
      "torch.return_types.sort(\n",
      "values=tensor([[-1.8518],\n",
      "        [-1.3720],\n",
      "        [-0.7140],\n",
      "        [-0.2899],\n",
      "        [ 0.9623],\n",
      "        [ 1.4051]]),\n",
      "indices=tensor([[0],\n",
      "        [4],\n",
      "        [2],\n",
      "        [5],\n",
      "        [1],\n",
      "        [3]]))\n",
      "torch.return_types.sort(\n",
      "values=tensor([[ 1.4051],\n",
      "        [ 0.9623],\n",
      "        [-0.2899],\n",
      "        [-0.7140],\n",
      "        [-1.3720],\n",
      "        [-1.8518]]),\n",
      "indices=tensor([[3],\n",
      "        [1],\n",
      "        [5],\n",
      "        [2],\n",
      "        [4],\n",
      "        [0]]))\n"
     ]
    }
   ],
   "source": [
    "# torch.sort()\n",
    "a = torch.randn(6,1)\n",
    "print(a)\n",
    "\n",
    "a_sorted = torch.sort(a, dim = 0) # 기본 오름차순 정렬\n",
    "print(a_sorted)\n",
    "\n",
    "a_sorted = torch.sort(a, dim = 0, descending = True) # 내림차순 정렬\n",
    "print(a_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5614c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5418, -0.3837],\n",
      "        [-0.5920,  0.6408],\n",
      "        [ 0.9517,  0.5600],\n",
      "        [ 0.7042,  0.1876],\n",
      "        [-0.2711,  0.8541]])\n",
      "tensor(0.2110)\n",
      "\n",
      "tensor([0.0502, 0.3717])\n",
      "tensor([0.0502, 0.3717])\n",
      "tensor([[0.0502, 0.3717]])\n",
      "\n",
      "tensor([-0.4627,  0.0244,  0.7558,  0.4459,  0.2915])\n",
      "tensor([-0.4627,  0.0244,  0.7558,  0.4459,  0.2915])\n",
      "tensor([[-0.4627],\n",
      "        [ 0.0244],\n",
      "        [ 0.7558],\n",
      "        [ 0.4459],\n",
      "        [ 0.2915]])\n"
     ]
    }
   ],
   "source": [
    "# torch.mean()\n",
    "t = 2 * torch.rand(5, 2) - 1\n",
    "print(t)\n",
    "\n",
    "# 텐서의 전체 평균  \n",
    "t1 = torch.mean(t)\n",
    "print(t1)\n",
    "print()\n",
    "\n",
    "t2 = torch.mean(t, axis = 0)\n",
    "t22 = torch.mean(t, dim = 0)\n",
    "t222 = torch.mean(t, dim = 0, keepdim = True)\n",
    "print(t2)\n",
    "print(t22)\n",
    "print(t222)\n",
    "print()\n",
    "\n",
    "t3 = torch.mean(t, axis = 1)\n",
    "t33 = torch.mean(t, dim = 1)\n",
    "t333 = torch.mean(t, dim = 1, keepdim = True)\n",
    "print(t3)\n",
    "print(t33)\n",
    "print(t333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abc4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2, 3, 4, 1, 3, 4, 4, 2, 2, 4])\n",
      "torch.Size([12])\n",
      "tensor([[[1, 1, 2],\n",
      "         [3, 4, 1]],\n",
      "\n",
      "        [[3, 4, 4],\n",
      "         [2, 2, 4]]])\n",
      "3\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([10])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "# torch.reshape()\n",
    "A = torch.randint(1, 5, size = (12,)) # 1부터 5미만 12개 정수 (1 차원은 (N,) 과 같이 표현)\n",
    "print(A)\n",
    "print(A.shape)\n",
    "\n",
    "B = A.reshape(2, 2, 3)\n",
    "print(B)\n",
    "print(B.ndim) # 3 차원 행렬이다\n",
    "\n",
    "t = torch.zeros(10)\n",
    "print(t)\n",
    "print(t.shape)\n",
    "\n",
    "t_reshape = t.reshape(2, 5)\n",
    "print(t_reshape)\n",
    "print(t_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19])\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19]])\n",
      "torch.Size([4, 5])\n",
      "torch.Size([2, 5, 2])\n",
      "torch.Size([2, 2, 5])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([20, 1])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(20,)\n",
    "print(A.shape)\n",
    "print(A)\n",
    "\n",
    "print(A.reshape(4,5))\n",
    "print(A.reshape(4, -1).shape) # 4개 행이 되도록 열의 수를 자동으로 맞춤\n",
    "print(A.reshape(2, 5,-1).shape) # 2 x 5 x 2\n",
    "print(A.reshape(2, -1, 5).shape)\n",
    "print(A.reshape(1, -1).shape) # 2차원 행 벡터\n",
    "print(A.reshape(-1, 1).shape) # 2차원 열 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor([[9]])\n",
      "tensor([[9]])\n",
      "tensor([[9]])\n",
      "tensor([[9]])\n",
      "torch.Size([3, 6, 4])\n",
      "torch.Size([4, 6, 3])\n",
      "torch.Size([4, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "# 내적\n",
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([2, 2, 1])\n",
    "print(torch.sum(a*b))\n",
    "\n",
    "a = a.reshape(3,1) # 3x1 벡터\n",
    "b = b.reshape(3,1) # 3x1 벡터\n",
    "print(a.transpose(1,0)@b) # 1번째 dim, 0번째 dim 자리 바꾸고 @ b\n",
    "print(a.permute(1,0)@b) # 0번째에는 1번째 값, 1번째에는 0번째 값으로 자리 바꾸고 @ b    \n",
    "print(a.T@b)\n",
    "print(a.t()@b)\n",
    "\n",
    "A = torch.randn(4,3,6)\n",
    "print(A.permute(1,2,0).shape)\n",
    "print(A.transpose(2,1).shape) # transpose 는 둘끼리 자리 바꾸기만 가능\n",
    "print(A.transpose(1,2).shape) # 즉, 위와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be226397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5, 6])\n",
      "torch.Size([4, 5, 6])\n",
      "torch.Size([4, 5, 6])\n",
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([3, 4, 6])\n",
      "torch.Size([3, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4, 5, 6)\n",
    "print(x.shape)\n",
    "\n",
    "print(x[1, 2, :, :, :].shape)\n",
    "print(x[1, 2, ...].shape) # x[1, 2, …] 는 x[1, 2, :, :, :] 와 같습니다.\n",
    "\n",
    "print(x[:, :, :, :, 3].shape)\n",
    "print(x[..., 3].shape) # x[…, 3] 는 x[:, :, :, :, 3] 와 같습니다.\n",
    "\n",
    "print(x[1, :, :, 3, :].shape)\n",
    "print(x[1, ..., 3, :].shape) # x[1, …, 3, :] 는 x[1, :, :, 3, :] 와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) torch.Size([6, 4])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.]]) torch.Size([3, 8])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]) torch.Size([6, 4])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.]]) torch.Size([3, 8])\n"
     ]
    }
   ],
   "source": [
    "A = torch.ones(3, 4)\n",
    "B = torch.zeros(3, 4)\n",
    "\n",
    "C = torch.vstack([A, B])\n",
    "D = torch.hstack([A, B]) # v는 0번째 차원, h는 1번째 차원에 쌓는다. (A,B 사이즈 (2,3,4)로 추가 해보기)\n",
    "E = torch.cat([A, B], dim = 0) # 0번째 차원에 대해서 concat. 즉, 6x4 됨\n",
    "F = torch.cat([A, B], dim = 1) # 1번째 차원에 대해서 concat. 즉, 3x8 됨\n",
    "# cat만 쓰면 vstack, hstack 안써도 된다.\n",
    "\n",
    "print(C, C.shape)\n",
    "print(D, D.shape)\n",
    "print(E, E.shape)\n",
    "print(F, F.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1c2067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 1, 4, 1])\n",
      "torch.Size([1, 2, 4, 1])\n",
      "torch.Size([1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 3, 1, 4, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# squeeze\n",
    "t = torch.zeros(1, 2, 1, 4, 1)\n",
    "t_sqz = torch.squeeze(t, dim = 2)\n",
    "\n",
    "print(t.shape)\n",
    "print(t_sqz.shape)\n",
    "\n",
    "A = torch.randn(1,1,1,3,1,1,1,4,1,1,1)\n",
    "\n",
    "print(A.shape)\n",
    "print(A.squeeze().shape)\n",
    "print(A.squeeze(dim=(0,2,4,5)).shape) # 0, 2, 4, 5번째 차원 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac87b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([3, 4, 1])\n",
      "torch.Size([1, 3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([3, 4, 1])\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze\n",
    "A = torch.randn(3,4)\n",
    "\n",
    "print(A.unsqueeze(dim=0).shape) # 0번째에 가상의 차원 추가\n",
    "print(A.unsqueeze(dim=1).shape)\n",
    "print(A.unsqueeze(dim=2).shape)\n",
    "\n",
    "# 위와 동일, 그러나 귀찮음\n",
    "print(A.reshape(1,3,4).shape)\n",
    "print(A.reshape(3,1,4).shape)\n",
    "print(A.reshape(3,4,1).shape)\n",
    "\n",
    "# unsqueeze 활용\n",
    "# A와 B를 2x3x4로 쌓고 싶을 때\n",
    "A = torch.ones(3,4)\n",
    "B = torch.zeros(3,4)\n",
    "A = A.unsqueeze(dim=0)\n",
    "B = B.unsqueeze(dim=0)\n",
    "C = torch.cat([A,B], dim=0)\n",
    "\n",
    "print(C)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04fa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# stack\n",
    "A = torch.ones(3, 4)\n",
    "B = torch.zeros(3, 4)\n",
    "C = torch.stack([A, B])\n",
    "\n",
    "print(C)\n",
    "# unsqueeze 안하고 stack 으로 하면 되긴 함.\n",
    "# (차원을 추가(default는 dim=0에)해서 쌓아줌)\n",
    "# 근데 차원을 추가해서 쌓는 방식이다보니 A,B shape이 완전히 일치해야 함.\n",
    "# concat은 달라도 쌓을 차원 이외 차원들만 맞으면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f01d0bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100,   2],\n",
      "        [  3,   4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[100,   2],\n",
      "        [  3,   4]])\n",
      "tensor([[100,   2],\n",
      "        [  3,   4]])\n"
     ]
    }
   ],
   "source": [
    "# clone\n",
    "A = torch.tensor([[1,2],[3,4]])\n",
    "B = A.clone()\n",
    "B[0,0]=100\n",
    "\n",
    "print(B)\n",
    "print(A)\n",
    "\n",
    "# 이건 A, B의 주소가 같아서 동시에 바뀜\n",
    "A = torch.tensor([[1,2],[3,4]])\n",
    "B = A\n",
    "B[0,0]=100\n",
    "\n",
    "print(B)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4dbd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10])\n",
      "torch.Size([32, 5, 10])\n",
      "torch.Size([32, 5, 10])\n"
     ]
    }
   ],
   "source": [
    "# 행렬곱 @\n",
    "A = torch.randn(5,7)\n",
    "B = torch.randn(7,10)\n",
    "C = A @ B\n",
    "print(C.shape) # 5x10\n",
    "\n",
    "A = torch.randn(32,5,7)\n",
    "B = torch.randn(32,7,10)\n",
    "C = A @ B\n",
    "print(C.shape) # 32x5x10\n",
    "\n",
    "# 이런것도 가능하긴 함.\n",
    "# B 7x10을 32개로 복제해서 행렬곱\n",
    "A = torch.randn(32, 5, 7)\n",
    "B = torch.randn(7, 10)\n",
    "C = A @ B\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d547d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = np.array([1,2,3])\n",
    "b = torch.tensor([1,2,3])\n",
    "\n",
    "# numpy에서 tensor로 변환\n",
    "A = torch.tensor(a)\n",
    "A1 = torch.from_numpy(a)\n",
    "\n",
    "# tensor에서 numpy로 변환\n",
    "B = b.numpy()\n",
    "B1 = np.array(b)\n",
    "\n",
    "print(type(A))\n",
    "print(type(A1))\n",
    "\n",
    "print(type(B))\n",
    "print(type(B1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af352884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1시간 14분"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
